{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install groq\n!pip install -qU langchain_community\n!pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:10:32.009361Z","iopub.execute_input":"2025-05-23T18:10:32.009637Z","iopub.status.idle":"2025-05-23T18:10:55.359536Z","shell.execute_reply.started":"2025-05-23T18:10:32.009610Z","shell.execute_reply":"2025-05-23T18:10:55.358348Z"}},"outputs":[{"name":"stdout","text":"Collecting groq\n  Downloading groq-0.25.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\nDownloading groq-0.25.0-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.25.0\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.3/438.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting pdfplumber\n  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (44.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\nDownloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nfrom groq import Groq\nfrom langchain_community.document_loaders import PDFPlumberLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:11:51.374093Z","iopub.execute_input":"2025-05-23T18:11:51.374468Z","iopub.status.idle":"2025-05-23T18:11:53.170717Z","shell.execute_reply.started":"2025-05-23T18:11:51.374435Z","shell.execute_reply":"2025-05-23T18:11:53.169685Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\n\nos.environ[\"GROQ_API_KEY\"] = \"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\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:11:59.215231Z","iopub.execute_input":"2025-05-23T18:11:59.215760Z","iopub.status.idle":"2025-05-23T18:11:59.220808Z","shell.execute_reply.started":"2025-05-23T18:11:59.215733Z","shell.execute_reply":"2025-05-23T18:11:59.219529Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"system_prompt = \"\"\"You are an AI assistant designed to extract structured resume data.\n                   Always respond with a strictly valid JSON object. Use `null` for missing values,\n                   ensuring compliance with JSON standards. Do not include explanations,\n                   comments, or any additional text outside the JSON structure.\n                \"\"\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:11:59.714091Z","iopub.execute_input":"2025-05-23T18:11:59.714440Z","iopub.status.idle":"2025-05-23T18:11:59.719801Z","shell.execute_reply.started":"2025-05-23T18:11:59.714418Z","shell.execute_reply":"2025-05-23T18:11:59.718762Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"human_prompt = \"\"\"\n             **Task:** Extract key information from the following resume text.\n\n            **Resume Text:**\n            {context}\n\n            **Instructions:**\n            Please extract the following information and format it in a clear structure:\n\n            1. **Contact Information:**\n            - Name:\n            - Email:\n            - Phone Number:\n            - Website/Portfolio/LinkedIn:\n            - Github Profile:\n\n            2. **Education:**\n            - Institution Name:\n            - Degree:\n            - Graduation Date:\n\n            3. **Experience:**\n            - Job Title:\n            - Company Name:\n            - Location:\n            - Dates of Employment:\n            - Description:\n\n            5. **Skills:**\n            - Skills:\n\n            **Question:**\n            Extract this information as a structured and valid JSON object. Use `null` for missing or unavailable valuesDo not include explanations,\n                   comments, or any additional text outside the JSON structure.\n        \"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:12:05.434774Z","iopub.execute_input":"2025-05-23T18:12:05.435107Z","iopub.status.idle":"2025-05-23T18:12:05.441425Z","shell.execute_reply.started":"2025-05-23T18:12:05.435086Z","shell.execute_reply":"2025-05-23T18:12:05.440089Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n\n# Initialize Groq client once\nclient = Groq()\n\n# Your system and human prompts (define these before the loop)\nsystem_prompt = system_prompt\nhuman_prompt = human_prompt\n\ndef clean_resume_data(json_data):\n    \"\"\"Clean and standardize the resume JSON data\"\"\"\n    # 1. Remove duplicate skills (case insensitive)\n    if 'skills' in json_data and isinstance(json_data['skills'], list):\n        seen_skills = set()\n        unique_skills = []\n        for skill in json_data['skills']:\n            lower_skill = skill.strip().lower()\n            if lower_skill not in seen_skills:\n                seen_skills.add(lower_skill)\n                unique_skills.append(skill.strip())\n        json_data['skills'] = unique_skills\n    \n    # 2. Standardize website/portfolio fields\n    website_aliases = [\n        'website', 'portfolio', 'linkedin', \n        'Website', 'Portfolio', 'LinkedIn',\n        'personal_website', 'webpage'\n    ]\n    \n    # Find the first existing website-related field\n    website_field = None\n    website_value = None\n    for field in website_aliases:\n        if field in json_data:\n            website_field = field\n            website_value = json_data[field]\n            break\n    \n    # Standardize to 'website' if we found a value\n    if website_field and website_value:\n        # Remove all website-related fields\n        for field in website_aliases:\n            if field in json_data:\n                del json_data[field]\n        # Add the standardized field\n        json_data['website'] = website_value.strip()\n    \n    return json_data\n\ndef extract_text_pdf(pdf_path):\n    loader = PDFPlumberLoader(pdf_path)\n    docs = loader.load()\n    text = ''\n    for doc in docs:\n        text += doc.page_content\n    return text\n\ndef process_resume(pdf_path, index):\n    # Extract text from PDF\n    context = extract_text_pdf(pdf_path)\n    \n    # Call LLM API\n    completion = client.chat.completions.create(\n        model=\"llama-3.3-70b-versatile\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": human_prompt.format(context=context)\n            }\n        ],\n        temperature=1,\n        max_completion_tokens=1024,\n        top_p=1,\n        stream=True,\n        stop=None,\n    )\n    \n    # Process the streamed output\n    output = \"\"\n    for chunk in completion:\n        content = chunk.choices[0].delta.content or \"\"\n        print(content, end=\"\")\n        output += content\n    \n    # Extract JSON content\n    json_start = output.find('{')\n    json_end = output.rfind('}') + 1\n    json_content = output[json_start:json_end]\n    \n    # Save JSON to file\n    try:\n        json_data = json.loads(json_content)\n        \n        # Clean and standardize the data\n        cleaned_data = clean_resume_data(json_data)\n        \n        output_filename = f\"Resume_data_pdf_{index}.json\"\n        with open(output_filename, 'w') as f:\n            json.dump(cleaned_data, f, indent=2)\n        print(f\"\\nJSON saved successfully to {output_filename}\")\n        return True\n    except json.JSONDecodeError as e:\n        print(f\"Error parsing JSON for {pdf_path}: {e}\")\n        # Save raw output for debugging\n        with open(f\"Raw_output_pdf_{index}.json\", 'w') as f:\n            f.write(output)\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:32:29.419869Z","iopub.execute_input":"2025-05-23T18:32:29.420248Z","iopub.status.idle":"2025-05-23T18:32:29.499580Z","shell.execute_reply.started":"2025-05-23T18:32:29.420225Z","shell.execute_reply":"2025-05-23T18:32:29.498506Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Process each PDF separately\npdf_paths = [pdf_path1,pdf_path2,pdf_path3,pdf_path4,pdf_path5]\nfor i, pdf_path in enumerate(pdf_paths, start=1):\n    print(f\"\\nProcessing resume {i}: {pdf_path}\")\n    process_resume(pdf_path, i)\n    print(f\"Completed processing {pdf_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T18:32:35.160345Z","iopub.execute_input":"2025-05-23T18:32:35.160713Z","iopub.status.idle":"2025-05-23T18:32:53.258925Z","shell.execute_reply.started":"2025-05-23T18:32:35.160689Z","shell.execute_reply":"2025-05-23T18:32:53.257647Z"}},"outputs":[{"name":"stdout","text":"\nProcessing resume 1: /kaggle/input/appprseinput/18448085.rank1.pdf\n```\n{\n  \"Contact Information\": {\n    \"Name\": null,\n    \"Email\": null,\n    \"Phone Number\": null,\n    \"Website/Portfolio/LinkedIn\": null,\n    \"Github Profile\": null\n  },\n  \"Education\": [\n    {\n      \"Institution Name\": \"Binghamton University, State University of New York\",\n      \"Degree\": \"Masters of Science : Industrial and Systems Engineering\",\n      \"Graduation Date\": \"Aug 2016\",\n      \"GPA\": \"3.51/4.00\"\n    },\n    {\n      \"Institution Name\": \"Osmania University\",\n      \"Degree\": \"Bachelors of Engineering : Mechanical Engineering\",\n      \"Graduation Date\": \"May 2014\",\n      \"GPA\": \"3.33/4.00\"\n    }\n  ],\n  \"Experience\": [\n    {\n      \"Job Title\": \"Data Analyst\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": \"State\",\n      \"Dates of Employment\": \"07/2016 to Current\",\n      \"Description\": null\n    },\n    {\n      \"Job Title\": \"Student Manager\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": \"State\",\n      \"Dates of Employment\": \"09/2015 to 05/2016\",\n      \"Description\": \"Undertook a leadership and advisory role in training newcomers to hone their culinary and behavioral skills.\"\n    },\n    {\n      \"Job Title\": \"Intern\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": null,\n      \"Dates of Employment\": \"06/2013 to 07/2013\",\n      \"Description\": \"Identified the areas in the assembly line of a light commercial vehicle where more operations could be housed. Developed a detailed model of improved layout to accommodate more operations using AutoCAD to improve the space utilization by 300%.\"\n    },\n    {\n      \"Job Title\": \"Consultant\",\n      \"Company Name\": null,\n      \"Location\": null,\n      \"Dates of Employment\": null,\n      \"Description\": \"Consulted a self-storage company to classify the customers as 'worthy' and 'not worthy' based on their activity on the company website using the Random Forest algorithm. Built the model in R and model deployment using Python. Currently building a reservation model for Public Storage to forecast if the customer would reserve the storage or not.\"\n    }\n  ],\n  \"Skills\": [\n    \"Apache\",\n    \"AutoCAD\",\n    \"charts\",\n    \"Credit\",\n    \"clients\",\n    \"Data Analysis\",\n    \"Data Visualization\",\n    \"Databases\",\n    \"Dec\",\n    \"decision-making\",\n    \"layout\",\n    \"leadership\",\n    \"MATLAB\",\n    \"Microsoft Access\",\n    \"MS Excel\",\n    \"Minitab\",\n    \"MySQL\",\n    \"Optimization\",\n    \"Oracle Database\",\n    \"Python\",\n    \"SAS\",\n    \"Simulation\",\n    \"Six Sigma\",\n    \"SPSS\",\n    \"SQL\",\n    \"Statistical Analysis\",\n    \"Tableau\",\n    \"Visio\",\n    \"website\"\n  ],\n  \"Projects\": [\n    {\n      \"Project Name\": \"Classification of Customers for Credit Card Company\",\n      \"Dates\": \"Jan 2016 - May 2016\",\n      \"Description\": \"Performed a logistic regression on a credit card company dataset to classify clients as credible and non-credible. Extracted crucial factors to simplify the classification model using exploratory factor analysis. Developed and validated a model to classify the future customers and aid decision-making.\"\n    },\n    {\n      \"Project Name\": \"Simulation Analysis of Adding a Second Parking Ticket Booth at a Mall\",\n      \"Dates\": \"Aug 2015 - Dec 2015\",\n      \"Description\": \"Assessed distribution and trends of incoming customer patterns performing statistical analysis on MATLAB and ExpertFit. Additional booth modeled using Arena reduced average waiting time per customer from 6.2 minutes to 1.8 minutes.\"\n    },\n    {\n      \"Project Name\": \"Statistical Analysis of Defects in Clutch Plate Manufacturing - A Six Sigma Study\",\n      \"Dates\": \"Jan 2015 - May 2015\",\n      \"Description\": \"The DMAIC methodology (Define, Measure, Analyze, Improve and Control) was implemented to understand the cause of the defects and data was statistically analyzed with the help of control charts using Minitab.\"\n    }\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_1.json\nCompleted processing /kaggle/input/appprseinput/18448085.rank1.pdf\n\nProcessing resume 2: /kaggle/input/appprseinput/83816738.rank2.pdf\n```json\n{\n  \"contactInformation\": {\n    \"name\": \"Sagun Pandey\",\n    \"email\": null,\n    \"phoneNumber\": null,\n    \"website\": \"www.sagunpandey.com\",\n    \"linkedin\": \"www.linkedin.com/in/sagunpandey\",\n    \"github\": \"www.github.com/sagunpandey\"\n  },\n  \"education\": [\n    {\n      \"institutionName\": \"Lamar University\",\n      \"degree\": \"Master of Science in Computer Science\",\n      \"graduationDate\": \"2017\",\n      \"gpa\": \"4.0/4.0\"\n    },\n    {\n      \"institutionName\": \"Tribhuvan University\",\n      \"degree\": \"Bachelor of Engineering in Electronics and Communication Engineering\",\n      \"graduationDate\": \"2013\",\n      \"gpa\": \"3.94/4.0\"\n    }\n  ],\n  \"experience\": [\n    {\n      \"jobTitle\": \"Information Technology Intern (Test Automation Engineer)\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"City, State\",\n      \"datesOfEmployment\": \"05/2017 - 08/2017\",\n      \"description\": \"Created test automation framework, automated regression testing, and integrated automated tests with Cucumber.\"\n    },\n    {\n      \"jobTitle\": \"Java Full Stack Developer\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"City, State\",\n      \"datesOfEmployment\": \"05/2014 - 06/2016\",\n      \"description\": \"Worked on varied aspects of application development, coded and debugged multi-tiered Java-based applications, and developed database access layers.\"\n    },\n    {\n      \"jobTitle\": \"Java Developer Intern\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"City, State\",\n      \"datesOfEmployment\": \"03/2014 - 05/2014\",\n      \"description\": \"Developed MRP reading module, utilized Java 1.7 and Java Swing, and prepared test plans for unit testing.\"\n    },\n    {\n      \"jobTitle\": \"Software Developer Intern\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"City, State\",\n      \"datesOfEmployment\": \"01/2013 - 10/2013\",\n      \"description\": \"Designed and developed applications using Scrum, performed back-end development using PHP, and built a file-crawler app.\"\n    }\n  ],\n  \"skills\": {\n    \"programmingLanguages\": [\"Java/J2EE\", \"JavaScript\", \"Android\", \"HTML\", \"CSS\", \"SQL\", \"C\", \"C\"],\n    \"frameworksAndLibraries\": [\"Spring\", \"Restful-Web Services\", \"Hibernate\", \"AngularJS\", \"ReactJS\", \"jQuery\", \"Bootstrap\", \"Selenium WebDriver\", \"Cucumber\"],\n    \"databases\": [\"MySQL\", \"PostgreSQL\", \"Oracle\", \"MongoDB\", \"H2\"],\n    \"buildTools\": [\"Gradle\", \"Maven\", \"Ant\"],\n    \"practices\": [\"Agile/Scrum\", \"Waterfall\", \"TDD\", \"Clean Coding\", \"Continuous Delivery\"],\n    \"architectures\": [\"Microservices\", \"Single Page Application\", \"REST\", \"Client/Server\"],\n    \"versionControl\": [\"SVN\", \"Git\"],\n    \"cloudApplicationPlatform\": [\"AWS\"],\n    \"others\": [\"Bower\", \"Grunt\", \"Npm\", \"Node\", \"JSON\", \"XML\", \"Jenkins\"],\n    \"ide\": [\"Eclipse\", \"IntelliJ\", \"Android Studio\"],\n    \"operatingSystems\": [\"Linux\", \"Windows\"]\n  }\n}\n```\nJSON saved successfully to Resume_data_pdf_2.json\nCompleted processing /kaggle/input/appprseinput/83816738.rank2.pdf\n\nProcessing resume 3: /kaggle/input/appprseinput/22946204.rank3.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": null,\n    \"Email\": null,\n    \"Phone Number\": null,\n    \"Website/Portfolio/LinkedIn\": null,\n    \"Github Profile\": null\n  },\n  \"Education\": [\n    {\n      \"Institution Name\": \"University of Pennsylvania, School of Eng. and Applied Science\",\n      \"Degree\": \"Master of Science : Mech. Eng. & Applied Mechanics\",\n      \"Graduation Date\": \"Jun\"\n    },\n    {\n      \"Institution Name\": \"Harbin Institute of Technology (HIT)\",\n      \"Degree\": \"Bachelor of Science : Mechanical Design and Automation\",\n      \"Graduation Date\": \"Aug\"\n    }\n  ],\n  \"Experience\": [\n    {\n      \"Job Title\": \"R&D Product Development Engineer\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": \"City\",\n      \"Dates of Employment\": \"June 2016 to Current\",\n      \"Description\": \"Design and build a tail-sitter VTOL(vertical take off and landing) UAV(unmanned aerial vehicle) which takes off and lands vertically and travels horizontally. Main duties include but not limit to aerodynamics modeling, UAV control system design, mechanical manufacturing, simulation and tuning/experiments.\"\n    },\n    {\n      \"Job Title\": \"Research assistant\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": \"City\",\n      \"Dates of Employment\": \"May 2015 to February 2016\",\n      \"Description\": \"Research assistant for Wharton School environment economics projects on Europe Emission Trading System (EU ETC). Main duties include large scale data collecting, cleaning, merging, database construction and data analysis, etc.\"\n    },\n    {\n      \"Job Title\": \"Mechanical Technician\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": \"City\",\n      \"Dates of Employment\": \"August 2013 to September 2013\",\n      \"Description\": \"Check, report on reducer components, automobile chassis producing, processing and assembly line. Trained in mechanical manufacturing fundamentals in industrial production of automobiles.\"\n    }\n  ],\n  \"Skills\": [\n    \"3D\",\n    \"assembly language\",\n    \"AutoCAD\",\n    \"automobiles\",\n    \"C\",\n    \"C language\",\n    \"CAD\",\n    \"Chinese\",\n    \"Clustering\",\n    \"com\",\n    \"controller\",\n    \"data analysis\",\n    \"Database\",\n    \"database software\",\n    \"designing\",\n    \"economics\",\n    \"Editing\",\n    \"embedded system\",\n    \"English\",\n    \"Experiments\",\n    \"GUI\",\n    \"graphic\",\n    \"Java\",\n    \"Laser\",\n    \"Lathe\",\n    \"Machine Learning\",\n    \"MATLAB\",\n    \"Mechanical\",\n    \"Mechanical Design\",\n    \"Mechanical Engineering\",\n    \"Excel\",\n    \"Windows 7\",\n    \"Word\",\n    \"Mill\",\n    \"Modeling\",\n    \"Networks\",\n    \"Neural\",\n    \"Operating Systems\",\n    \"OS\",\n    \"painting\",\n    \"camera\",\n    \"PLC\",\n    \"predict\",\n    \"producing\",\n    \"Programming\",\n    \"Python\",\n    \"Rendering\",\n    \"Research\",\n    \"Robotics\",\n    \"Simulation\",\n    \"Solidworks\",\n    \"SPSS\",\n    \"SQL\",\n    \"SQL Server\",\n    \"STATA\",\n    \"Statistics\",\n    \"system design\",\n    \"Trading System\",\n    \"vision\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_3.json\nCompleted processing /kaggle/input/appprseinput/22946204.rank3.pdf\n\nProcessing resume 4: /kaggle/input/appprseinput/50328713.rank4.pdf\n```\n{\n  \"contactInformation\": {\n    \"name\": \"Chu-Hsiang Wu\",\n    \"email\": null,\n    \"phoneNumber\": null,\n    \"websitePortfolioLinkedIn\": null,\n    \"githubProfile\": null\n  },\n  \"education\": [\n    {\n      \"institutionName\": \"UT Austin\",\n      \"degree\": \"Ph.D\",\n      \"graduationDate\": \"May 2018\",\n      \"fieldOfStudy\": \"Petroleum Engineering\"\n    },\n    {\n      \"institutionName\": \"National Taiwan University\",\n      \"degree\": \"M.S\",\n      \"graduationDate\": \"Jun. 2010\",\n      \"fieldOfStudy\": \"Mechanical Engineering\"\n    },\n    {\n      \"institutionName\": \"National Tsing Hua University\",\n      \"degree\": \"B.S\",\n      \"graduationDate\": \"Jun. 2008\",\n      \"fieldOfStudy\": \"Power Mechanical Engineering\"\n    }\n  ],\n  \"experience\": [\n    {\n      \"jobTitle\": \"ENGINEERING INTERN\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"State\",\n      \"datesOfEmployment\": \"08/2016 - 12/2016\",\n      \"description\": \"Developed a cavings transport model for optimizing hole-cleaning operations.\"\n    },\n    {\n      \"jobTitle\": \"ENGINEERING INTERN\",\n      \"companyName\": null,\n      \"location\": \"City, State\",\n      \"datesOfEmployment\": \"05/2016 - 08/2016\",\n      \"description\": \"Optimize diverter pumping schedule for better production performance after well re-stimulation.\"\n    },\n    {\n      \"jobTitle\": \"PROCESS ENGINEER\",\n      \"companyName\": \"Company Name\",\n      \"location\": \"City\",\n      \"datesOfEmployment\": \"04/2012 - 05/2013\",\n      \"description\": \"Improve display yield through statistical modeling, process control, and tool modifications.\"\n    }\n  ],\n  \"skills\": [\n    \"C++\",\n    \"Python\",\n    \"MATLAB\",\n    \"Git\",\n    \"Bash\",\n    \"R\",\n    \"SQL\",\n    \"Machine Learning\",\n    \"Scikit-learn\",\n    \"Pandas\",\n    \"Seaborn\",\n    \"matplotlib\",\n    \"TensorFlow\",\n    \"CFD-DEM\",\n    \"OpenFOAM\",\n    \"CFD-ACE+\",\n    \"Fluent\",\n    \"COMSOL\",\n    \"LAMMPS\",\n    \"LIGGGHTS\",\n    \"SEM\",\n    \"AFM\",\n    \"Confocal Microscopy\",\n    \"Regression analysis\",\n    \"Statistical process control\",\n    \"Design of experiments\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_4.json\nCompleted processing /kaggle/input/appprseinput/50328713.rank4.pdf\n\nProcessing resume 5: /kaggle/input/appprseinput/17823436.rank5.pdf\n```json\n{\n  \"Contact Information\": {\n    \"Name\": \"Aaditya Vijay Hirurkar\",\n    \"Email\": null,\n    \"Phone Number\": null,\n    \"Website/Portfolio/LinkedIn\": null,\n    \"Github Profile\": null\n  },\n  \"Education\": {\n    \"Institution Name\": \"University of Mumbai\",\n    \"Degree\": \"Bachelor of Engineering, Information Technology\",\n    \"Graduation Date\": \"2008\"\n  },\n  \"Experience\": [\n    {\n      \"Job Title\": \"Business Analyst Sr. Technical Business Analyst\",\n      \"Company Name\": \"Company Name\",\n      \"Location\": null,\n      \"Dates of Employment\": \"Jul 2011 to Dec 2013\",\n      \"Description\": \"Requirement Gathering, Requirement Analysis, Release management, Product management, Product implementation role, BRS analysis, Feasibility analysis, Vender management, Client handling, Product Management\"\n    },\n    {\n      \"Job Title\": \"Software Implementation Engineer\",\n      \"Company Name\": \"Base Information Management Pvt. Ltd.\",\n      \"Location\": null,\n      \"Dates of Employment\": \"Dec 2008 to Jul 2011\",\n      \"Description\": \"Communicate directly with the client and gather details of requirement, Documentation, Designing screen layouts, Interact with development team, QC team for effective solution\"\n    }\n  ],\n  \"Skills\": [\n    \"C\",\n    \"C++\",\n    \"Core Java\",\n    \"Oracle 9i\",\n    \"MS SQL Server-2005\",\n    \"IBM DB2\",\n    \"UML\",\n    \"HTML\",\n    \"XML\",\n    \"Windows 9X/XP/2000/2003 Server\",\n    \"Linux Red hat 5\",\n    \"SUSE 11\",\n    \"Rational Rose\",\n    \"MS Visio\",\n    \"MS Project\",\n    \"Oracle SQL Developer\",\n    \"Crystal Reports\",\n    \"Java Workflow Editor\",\n    \"Eclipse\",\n    \"Jboss\",\n    \"Tomcat5\",\n    \"IBM Websphere App Server 7\"\n  ]\n}\n```\nJSON saved successfully to Resume_data_pdf_5.json\nCompleted processing /kaggle/input/appprseinput/17823436.rank5.pdf\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}